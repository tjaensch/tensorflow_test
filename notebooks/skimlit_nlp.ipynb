{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
       " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt',\n",
       " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "filenames = [data_dir + f for f in os.listdir(data_dir)]\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to read the lines of a file\n",
    "def get_lines(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a preprocessing function that returns a dictionary\n",
    "def preprocess_text_with_line_numbers(filename):\n",
    "  \"\"\"Returns a list of dictionaries of abstract line data.\n",
    "\n",
    "  Takes in filename, reads its contents and sorts through each line,\n",
    "  extracting things like the target label, the text of the sentence,\n",
    "  how many sentences are in the current abstract and what sentence number\n",
    "  the target line is.\n",
    "\n",
    "  Args:\n",
    "      filename: a string of the target text file to read and extract line data\n",
    "      from.\n",
    "\n",
    "  Returns:\n",
    "      A list of dictionaries each containing a line from an abstract,\n",
    "      the lines label, the lines position in the abstract and the total number\n",
    "      of lines in the abstract where the line is from. For example:\n",
    "\n",
    "      [{\"target\": 'CONCLUSION',\n",
    "        \"text\": The study couldn't have gone better, turns out people are kinder than you think\",\n",
    "        \"line_number\": 8,\n",
    "        \"total_lines\": 8}]\n",
    "  \"\"\"\n",
    "  input_lines = get_lines(filename) # get all lines from filename\n",
    "  abstract_lines = \"\" # create an empty abstract\n",
    "  abstract_samples = [] # create an empty list of abstracts\n",
    "  \n",
    "  # Loop through each line in target file\n",
    "  for line in input_lines:\n",
    "    if line.startswith(\"###\"): # check to see if line is an ID line\n",
    "      abstract_id = line\n",
    "      abstract_lines = \"\" # reset abstract string\n",
    "    elif line.isspace(): # check to see if line is a new line\n",
    "      abstract_line_split = abstract_lines.splitlines() # split abstract into separate lines\n",
    "\n",
    "      # Iterate through each line in abstract and count them at the same time\n",
    "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
    "        line_data = {} # create empty dict to store data from line\n",
    "        target_text_split = abstract_line.split(\"\\t\") # split target label from text\n",
    "        line_data[\"target\"] = target_text_split[0] # get target label\n",
    "        line_data[\"text\"] = target_text_split[1].lower() # get target text and lower it\n",
    "        line_data[\"line_number\"] = abstract_line_number # what number line does the line appear in the abstract?\n",
    "        line_data[\"total_lines\"] = len(abstract_line_split) - 1 # how many total lines are in the abstract? (start from 0)\n",
    "        abstract_samples.append(line_data) # add line data to abstract samples list\n",
    "    \n",
    "    else: # if the above conditions aren't fulfilled, the line contains a labelled sentence\n",
    "      abstract_lines += line\n",
    "  \n",
    "  return abstract_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 9.06 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(180040, 30212, 30135)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data from file and preprocess it\n",
    "%time\n",
    "train_samples = preprocess_text_with_line_numbers(data_dir + \"train.txt\")\n",
    "val_samples = preprocess_text_with_line_numbers(data_dir + \"dev.txt\")\n",
    "test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")\n",
    "\n",
    "len(train_samples), len(val_samples), len(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>line_number</th>\n",
       "      <th>total_lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>a total of @ patients with primary knee oa wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>outcome measures included pain reduction and i...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>pain was assessed using the visual analog pain...</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>secondary outcome measures included the wester...</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>there was a clinically relevant reduction in t...</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>the mean difference between treatment arms ( @...</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>further , there was a clinically relevant redu...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>these differences remained significant at @ we...</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>the outcome measures in rheumatology clinical ...</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CONCLUSIONS</td>\n",
       "      <td>low-dose oral prednisolone had both a short-te...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>emotional eating is associated with overeating...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>yet , empirical evidence for individual ( trai...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target                                               text  \\\n",
       "0     OBJECTIVE  to investigate the efficacy of @ weeks of dail...   \n",
       "1       METHODS  a total of @ patients with primary knee oa wer...   \n",
       "2       METHODS  outcome measures included pain reduction and i...   \n",
       "3       METHODS  pain was assessed using the visual analog pain...   \n",
       "4       METHODS  secondary outcome measures included the wester...   \n",
       "5       METHODS  serum levels of interleukin @ ( il-@ ) , il-@ ...   \n",
       "6       RESULTS  there was a clinically relevant reduction in t...   \n",
       "7       RESULTS  the mean difference between treatment arms ( @...   \n",
       "8       RESULTS  further , there was a clinically relevant redu...   \n",
       "9       RESULTS  these differences remained significant at @ we...   \n",
       "10      RESULTS  the outcome measures in rheumatology clinical ...   \n",
       "11  CONCLUSIONS  low-dose oral prednisolone had both a short-te...   \n",
       "12   BACKGROUND  emotional eating is associated with overeating...   \n",
       "13   BACKGROUND  yet , empirical evidence for individual ( trai...   \n",
       "\n",
       "    line_number  total_lines  \n",
       "0             0           11  \n",
       "1             1           11  \n",
       "2             2           11  \n",
       "3             3           11  \n",
       "4             4           11  \n",
       "5             5           11  \n",
       "6             6           11  \n",
       "7             7           11  \n",
       "8             8           11  \n",
       "9             9           11  \n",
       "10           10           11  \n",
       "11           11           11  \n",
       "12            0           10  \n",
       "13            1           10  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(train_samples)\n",
    "val_df = pd.DataFrame(val_samples)\n",
    "test_df = pd.DataFrame(test_samples)\n",
    "train_df.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180040, 30212, 30135)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert abstract text lines into lists \n",
    "train_sentences = train_df[\"text\"].tolist()\n",
    "val_sentences = val_df[\"text\"].tolist()\n",
    "test_sentences = test_df[\"text\"].tolist()\n",
    "len(train_sentences), len(val_sentences), len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "train_labels_one_hot = one_hot_encoder.fit_transform(train_df[\"target\"].values.reshape(-1, 1))\n",
    "val_labels_one_hot = one_hot_encoder.fit_transform(val_df[\"target\"].values.reshape(-1, 1))\n",
    "test_labels_one_hot = one_hot_encoder.fit_transform(test_df[\"target\"].values.reshape(-1, 1))\n",
    "\n",
    "train_labels_one_hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 2, ..., 4, 1, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "train_labels_encoded = label_encoder.fit_transform(train_df[\"target\"])\n",
    "val_labels_encoded = label_encoder.fit_transform(val_df[\"target\"])\n",
    "test_labels_encoded = label_encoder.fit_transform(test_df[\"target\"])\n",
    "\n",
    "train_labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(label_encoder.classes_)\n",
    "class_names = label_encoder.classes_\n",
    "num_classes, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors\n"
     ]
    }
   ],
   "source": [
    "# Getting the path of the glove embedding (using 100D)\n",
    "import numpy as np \n",
    "glove_path = 'glove.6B.100d.txt'\n",
    "\n",
    "embedding_index = {}\n",
    "\n",
    "# Making dict of vector representtion of the words (s --> [8, 48......])\n",
    "with open(glove_path) as f:\n",
    "  for line in f:\n",
    "    \n",
    "    # Getting the words and coef in a variable \n",
    "    word , coefs = line.split(maxsplit = 1)\n",
    "    coefs = np.fromstring(coefs , 'f' , sep = ' ')\n",
    "    \n",
    "    # Adding the coefs to our embedding dict \n",
    "    embedding_index[word] = coefs\n",
    "\n",
    "print(f'Found {len(embedding_index)} word vectors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target': 'OBJECTIVE',\n",
       "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
       "  'line_number': 0,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       "  'line_number': 1,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       "  'line_number': 2,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       "  'line_number': 3,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
       "  'line_number': 4,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
       "  'line_number': 5,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
       "  'line_number': 6,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
       "  'line_number': 7,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
       "  'line_number': 8,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'these differences remained significant at @ weeks .',\n",
       "  'line_number': 9,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n",
       "  'line_number': 10,\n",
       "  'total_lines': 11},\n",
       " {'target': 'CONCLUSIONS',\n",
       "  'text': 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n",
       "  'line_number': 11,\n",
       "  'total_lines': 11},\n",
       " {'target': 'BACKGROUND',\n",
       "  'text': 'emotional eating is associated with overeating and the development of obesity .',\n",
       "  'line_number': 0,\n",
       "  'total_lines': 10},\n",
       " {'target': 'BACKGROUND',\n",
       "  'text': 'yet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .',\n",
       "  'line_number': 1,\n",
       "  'total_lines': 10}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first abstract of our training data\n",
    "train_samples[:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
       " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
       " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
       " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
       " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
       " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
       " 'these differences remained significant at @ weeks .']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View first 10 lines of training sentences\n",
    "train_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get class names and number of classes from LabelEncoder instance \n",
    "num_classes = len(label_encoder.classes_)\n",
    "class_names = label_encoder.classes_\n",
    "num_classes, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a pipeline\n",
    "model_0 = Pipeline([\n",
    "  (\"tf-idf\", TfidfVectorizer()),\n",
    "  (\"clf\", MultinomialNB())\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model_0.fit(X=train_sentences, \n",
    "            y=train_labels_encoded);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7218323844829869"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate baseline on validation dataset\n",
    "model_0.score(X=val_sentences,\n",
    "              y=val_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 3, ..., 4, 4, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import calculate_results helper function\n",
    "from helper_functions import calculate_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 72.1832384482987,\n",
       " 'precision': 0.7186466952323352,\n",
       " 'recall': 0.7218323844829869,\n",
       " 'f1': 0.6989250353450294}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate baseline results\n",
    "baseline_results = calculate_results(y_true=val_labels_encoded,\n",
    "                                     y_pred=baseline_preds)\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.338269273494777"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How long is each sentence on average?\n",
    "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
    "avg_sent_len = np.mean(sent_lens)\n",
    "avg_sent_len # return average sentence length (in tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What's the distribution look like?\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(sent_lens, bins=7);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How long of a sentence covers 95% of the lengths?\n",
    "output_seq_len = int(np.percentile(sent_lens, 95))\n",
    "output_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maximum sentence length in the training set\n",
    "max(sent_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many words are in our vocabulary? (taken from 3.2 in https://arxiv.org/pdf/1710.06071.pdf)\n",
    "max_tokens = 68000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-17 14:37:49.530110: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Create text vectorizer\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=max_tokens, # number of words in vocabulary\n",
    "                                    output_sequence_length=55) # desired output length of vectorized sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt text vectorizer to training sentences\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      "mean bias sd between tpd by segment and the visual scoring in the patients was @ @ ( r ( @ ) = @ ) for stress-induced ischemia and -@ @ ( r ( @ ) = @ ) for infarction .\n",
      "\n",
      "Length of text: 42\n",
      "\n",
      "Vectorized text:\n",
      "[[   57  2088   357    30 19422    22  3298     3     2   290  2359     5\n",
      "      2    12    10   491    11 10147  2345     3   491    11   641     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "# Test out text vectorizer\n",
    "import random\n",
    "target_sentence = random.choice(train_sentences)\n",
    "print(f\"Text:\\n{target_sentence}\")\n",
    "print(f\"\\nLength of text: {len(target_sentence.split())}\")\n",
    "print(f\"\\nVectorized text:\\n{text_vectorizer([target_sentence])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocabulary: 64841\n",
      "Most common words in the vocabulary: ['', '[UNK]', 'the', 'and', 'of']\n",
      "Least common words in the vocabulary: ['aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"
     ]
    }
   ],
   "source": [
    "# How many words in our training vocabulary?\n",
    "rct_20k_text_vocab = text_vectorizer.get_vocabulary()\n",
    "print(f\"Number of words in vocabulary: {len(rct_20k_text_vocab)}\"), \n",
    "print(f\"Most common words in the vocabulary: {rct_20k_text_vocab[:5]}\")\n",
    "print(f\"Least common words in the vocabulary: {rct_20k_text_vocab[-5:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'text_vectorization',\n",
       " 'trainable': True,\n",
       " 'batch_input_shape': (None,),\n",
       " 'dtype': 'string',\n",
       " 'max_tokens': 68000,\n",
       " 'standardize': 'lower_and_strip_punctuation',\n",
       " 'split': 'whitespace',\n",
       " 'ngrams': None,\n",
       " 'output_mode': 'int',\n",
       " 'output_sequence_length': 55,\n",
       " 'pad_to_max_tokens': False,\n",
       " 'sparse': False,\n",
       " 'ragged': False,\n",
       " 'vocabulary': None,\n",
       " 'idf_weights': None}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the config of our text vectorizer\n",
    "text_vectorizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence before vectorization:\n",
      "mean bias sd between tpd by segment and the visual scoring in the patients was @ @ ( r ( @ ) = @ ) for stress-induced ischemia and -@ @ ( r ( @ ) = @ ) for infarction .\n",
      "\n",
      "Sentence after vectorization (before embedding):\n",
      "[[   57  2088   357    30 19422    22  3298     3     2   290  2359     5\n",
      "      2    12    10   491    11 10147  2345     3   491    11   641     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]]\n",
      "\n",
      "Sentence after embedding:\n",
      "[[[-0.03877146 -0.00542033  0.04014592 ...  0.02477086 -0.03894208\n",
      "    0.01274638]\n",
      "  [ 0.03548434 -0.02410787  0.04756499 ... -0.00132295  0.01060746\n",
      "   -0.03646342]\n",
      "  [ 0.02542912  0.00041927 -0.01922756 ...  0.03220377  0.00875346\n",
      "    0.01839823]\n",
      "  ...\n",
      "  [-0.00118109  0.03632618  0.01622511 ... -0.00472263 -0.01563256\n",
      "    0.03397813]\n",
      "  [-0.00118109  0.03632618  0.01622511 ... -0.00472263 -0.01563256\n",
      "    0.03397813]\n",
      "  [-0.00118109  0.03632618  0.01622511 ... -0.00472263 -0.01563256\n",
      "    0.03397813]]]\n",
      "\n",
      "Embedded sentence shape: (1, 55, 128)\n"
     ]
    }
   ],
   "source": [
    "# Create token embedding layer\n",
    "token_embed = layers.Embedding(input_dim=len(rct_20k_text_vocab),\n",
    "                                 output_dim=128,\n",
    "                                    mask_zero=True,\n",
    "                                    name=\"token_embed\")\n",
    "\n",
    "# Show example embedding\n",
    "print(f\"Sentence before vectorization:\\n{target_sentence}\\n\")\n",
    "vectorized_sentence = text_vectorizer([target_sentence])\n",
    "print(f\"Sentence after vectorization (before embedding):\\n{vectorized_sentence}\\n\")\n",
    "embedded_sentence = token_embed(vectorized_sentence)\n",
    "print(f\"Sentence after embedding:\\n{embedded_sentence}\\n\")\n",
    "print(f\"Embedded sentence shape: {embedded_sentence.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((), (5,)), types: (tf.string, tf.float64)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn our data into TensorFlow Datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None,), (None, 5)), types: (tf.string, tf.float64)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the TensorSliceDataset's and turn them into prefetched batches\n",
    "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 1D convolutional model to process sequences\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "text_vectors = text_vectorizer(inputs) # vectorize text inputs\n",
    "token_embeddings = token_embed(text_vectors) # create embedding\n",
    "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(token_embeddings)\n",
    "x = layers.GlobalAveragePooling1D()(x) # condense the output of our feature vector\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "model_1 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile\n",
    "model_1.compile(loss=\"categorical_crossentropy\", # if your labels are integer form (not one hot) use sparse_categorical_crossentropy\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 55)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " token_embed (Embedding)     (None, 55, 128)           8299648   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 55, 64)            41024     \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 64)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,340,997\n",
      "Trainable params: 8,340,997\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 45s 79ms/step - loss: 0.9050 - accuracy: 0.6435 - val_loss: 0.6770 - val_accuracy: 0.7434\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 44s 79ms/step - loss: 0.6537 - accuracy: 0.7572 - val_loss: 0.6244 - val_accuracy: 0.7726\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 43s 77ms/step - loss: 0.6160 - accuracy: 0.7750 - val_loss: 0.5943 - val_accuracy: 0.7872\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_1_history = model_1.fit(train_dataset,\n",
    "                              steps_per_epoch=int(0.1 * len(train_dataset)), # only fit on 10% of batches for faster training time\n",
    "                              epochs=3,\n",
    "                              validation_data=valid_dataset,\n",
    "                              validation_steps=int(0.1 * len(valid_dataset))) # only validate on 10% of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 2s 2ms/step - loss: 0.5976 - accuracy: 0.7856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5975614190101624, 0.7856149673461914]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.00993913e-01, 1.94362864e-01, 1.02629706e-01, 2.68910319e-01,\n",
       "        3.31032127e-02],\n",
       "       [4.67539519e-01, 2.76620805e-01, 1.31997745e-02, 2.34784499e-01,\n",
       "        7.85539579e-03],\n",
       "       [1.26543567e-01, 4.14289068e-03, 1.75645365e-03, 8.67519379e-01,\n",
       "        3.77372489e-05],\n",
       "       ...,\n",
       "       [2.44143257e-06, 7.76696426e-04, 6.29427144e-04, 3.32551690e-06,\n",
       "        9.98588026e-01],\n",
       "       [4.59954701e-02, 4.71304744e-01, 1.07002325e-01, 5.71040958e-02,\n",
       "        3.18593413e-01],\n",
       "       [1.98140725e-01, 6.52669907e-01, 4.06398140e-02, 4.26981710e-02,\n",
       "        6.58513159e-02]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions (our model outputs prediction probabilities for each class)\n",
    "model_1_pred_probs = model_1.predict(valid_dataset)\n",
    "model_1_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 1, 1])>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert pred probs to classes\n",
    "model_1_preds = tf.argmax(model_1_pred_probs, axis=1)\n",
    "model_1_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.56149874222163,\n",
       " 'precision': 0.7822981431462142,\n",
       " 'recall': 0.7856149874222164,\n",
       " 'f1': 0.7831489537797054}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_1 results\n",
    "model_1_results = calculate_results(y_true=val_labels_encoded,\n",
    "                                    y_pred=model_1_preds)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 1D convolutional model to process sequences\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "text_vectors = text_vectorizer(inputs) # vectorize text inputs\n",
    "token_embeddings = token_embed(text_vectors) # create embedding\n",
    "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(token_embeddings)\n",
    "x = layers.GlobalAveragePooling1D()(x) # condense the output of our feature vector\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "model_1 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile\n",
    "model_1.compile(loss=\"categorical_crossentropy\", # if your labels are integer form (not one hot) use sparse_categorical_crossentropy\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 55)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " token_embed (Embedding)     (None, 55, 128)           8299648   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 55, 64)            41024     \n",
      "                                                                 \n",
      " global_average_pooling1d_1   (None, 64)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,340,997\n",
      "Trainable params: 8,340,997\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get summary of Conv1D model\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 43s 75ms/step - loss: 0.6605 - accuracy: 0.7627 - val_loss: 0.6069 - val_accuracy: 0.7809\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 41s 73ms/step - loss: 0.4935 - accuracy: 0.8273 - val_loss: 0.6002 - val_accuracy: 0.7799\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 44s 78ms/step - loss: 0.4768 - accuracy: 0.8317 - val_loss: 0.5916 - val_accuracy: 0.7842\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_1_history = model_1.fit(train_dataset,\n",
    "                              steps_per_epoch=int(0.1 * len(train_dataset)), # only fit on 10% of batches for faster training time\n",
    "                              epochs=3,\n",
    "                              validation_data=valid_dataset,\n",
    "                              validation_steps=int(0.1 * len(valid_dataset))) # only validate on 10% of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 1s 2ms/step - loss: 0.5957 - accuracy: 0.7859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.595680296421051, 0.7859128713607788]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on whole validation dataset (we only validated on 10% of batches during training)\n",
    "model_1.evaluate(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pretrained TensorFlow Hub USE\n",
    "import tensorflow_hub as hub\n",
    "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                        trainable=False,\n",
    "                                        name=\"universal_sentence_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random training sentence:\n",
      "logistic regression models with random effects for cluster and adjustment for baseline risk factors were calculated .\n",
      "\n",
      "Sentence after embedding:\n",
      "[-0.01793578 -0.05653007 -0.05616464 -0.01568629 -0.05693802 -0.06362107\n",
      " -0.04903462 -0.01952055 -0.02319945  0.06823134  0.06496425 -0.01603822\n",
      " -0.02962447  0.02667985 -0.03811573 -0.00258491 -0.050387   -0.00632235\n",
      "  0.04205893  0.03159961 -0.05014842  0.06521561 -0.02515312  0.03712993\n",
      "  0.07212263  0.06163865  0.00258032  0.06342252  0.02976707  0.02943256] (truncated output)...\n",
      "\n",
      "Length of sentence embedding:\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "# Test out the embedding on a random sentence\n",
    "random_training_sentence = random.choice(train_sentences)\n",
    "print(f\"Random training sentence:\\n{random_training_sentence}\\n\")\n",
    "use_embedded_sentence = tf_hub_embedding_layer([random_training_sentence])\n",
    "print(f\"Sentence after embedding:\\n{use_embedded_sentence[0][:30]} (truncated output)...\\n\")\n",
    "print(f\"Length of sentence embedding:\\n{len(use_embedded_sentence[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature extractor model using TF Hub layer\n",
    "inputs = layers.Input(shape=[], dtype=tf.string)\n",
    "pretrained_embedding = tf_hub_embedding_layer(inputs) # tokenize text and create embedding\n",
    "x = layers.Dense(128, activation=\"relu\")(pretrained_embedding) # add a fully connected layer on top of the embedding\n",
    "# Note: you could add more layers here if you wanted to\n",
    "outputs = layers.Dense(5, activation=\"softmax\")(x) # create the output layer\n",
    "model_2 = tf.keras.Model(inputs=inputs,\n",
    "                        outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model_2.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 7s 9ms/step - loss: 0.9178 - accuracy: 0.6503 - val_loss: 0.7947 - val_accuracy: 0.6905\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 5s 8ms/step - loss: 0.7680 - accuracy: 0.7016 - val_loss: 0.7533 - val_accuracy: 0.7031\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 5s 8ms/step - loss: 0.7514 - accuracy: 0.7124 - val_loss: 0.7386 - val_accuracy: 0.7124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17d26e6a0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit feature extractor model for 3 epochs\n",
    "model_2.fit(train_dataset,\n",
    "            steps_per_epoch=int(0.1 * len(train_dataset)),\n",
    "            epochs=3,\n",
    "            validation_data=valid_dataset,\n",
    "            validation_steps=int(0.1 * len(valid_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 6s 7ms/step - loss: 0.7413 - accuracy: 0.7140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7413101196289062, 0.7140209078788757]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on whole validation dataset\n",
    "model_2.evaluate(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l o g i s t i c   r e g r e s s i o n   m o d e l s   w i t h   r a n d o m   e f f e c t s   f o r   c l u s t e r   a n d   a d j u s t m e n t   f o r   b a s e l i n e   r i s k   f a c t o r s   w e r e   c a l c u l a t e d   .'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make function to split sentences into characters\n",
    "def split_chars(text):\n",
    "  return \" \".join(list(text))\n",
    "\n",
    "# Test splitting non-character-level sequence into characters\n",
    "split_chars(random_training_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t o   i n v e s t i g a t e   t h e   e f f i c a c y   o f   @   w e e k s   o f   d a i l y   l o w - d o s e   o r a l   p r e d n i s o l o n e   i n   i m p r o v i n g   p a i n   ,   m o b i l i t y   ,   a n d   s y s t e m i c   l o w - g r a d e   i n f l a m m a t i o n   i n   t h e   s h o r t   t e r m   a n d   w h e t h e r   t h e   e f f e c t   w o u l d   b e   s u s t a i n e d   a t   @   w e e k s   i n   o l d e r   a d u l t s   w i t h   m o d e r a t e   t o   s e v e r e   k n e e   o s t e o a r t h r i t i s   (   o a   )   .\n"
     ]
    }
   ],
   "source": [
    "# Split sequence-level data splits into character-level data splits\n",
    "train_chars = [split_chars(sentence) for sentence in train_sentences]\n",
    "val_chars = [split_chars(sentence) for sentence in val_sentences]\n",
    "test_chars = [split_chars(sentence) for sentence in test_sentences]\n",
    "print(train_chars[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149.3662574983337"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's the average character length?\n",
    "char_lens = [len(sentence) for sentence in train_sentences]\n",
    "mean_char_len = np.mean(char_lens)\n",
    "mean_char_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the distribution of our sequences at character-level\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(char_lens, bins=7);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find what character length covers 95% of sequences\n",
    "output_seq_char_len = int(np.percentile(char_lens, 95))\n",
    "output_seq_char_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all keyboard characters for char-level embedding\n",
    "import string\n",
    "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
    "alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create char-level token vectorizer instance\n",
    "NUM_CHAR_TOKENS = len(alphabet) + 2 # num characters in alphabet + space + OOV token\n",
    "char_vectorizer = TextVectorization(max_tokens=NUM_CHAR_TOKENS,  \n",
    "                                    output_sequence_length=output_seq_char_len,\n",
    "                                    standardize=\"lower_and_strip_punctuation\",\n",
    "                                    name=\"char_vectorizer\")\n",
    "\n",
    "# Adapt character vectorizer to training characters\n",
    "char_vectorizer.adapt(train_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different characters in character vocab: 28\n",
      "5 most common characters: ['', '[UNK]', 'e', 't', 'i']\n",
      "5 least common characters: ['k', 'x', 'z', 'q', 'j']\n"
     ]
    }
   ],
   "source": [
    "# Check character vocabulary characteristics\n",
    "char_vocab = char_vectorizer.get_vocabulary()\n",
    "print(f\"Number of different characters in character vocab: {len(char_vocab)}\")\n",
    "print(f\"5 most common characters: {char_vocab[:5]}\")\n",
    "print(f\"5 least common characters: {char_vocab[-5:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charified text:\n",
      "a   c l u s t e r   r a n d o m i z e d   t r i a l   w a s   c o n d u c t e d   i n   t h e   p l a t e a u x   r e g i o n   o f   t o g o   t o   e v a l u a t e   t h e   e f f e c t i v e n e s s   o f   d i f f e r e n t   a p p r o a c h e s   t o   p o s t - l l i n   c a m p a i g n   h o m e   v i s i t s   (   n u m b e r   o f   v i s i t s   a n d   t i m i n g   )   b y   v o l u n t e e r s   t o   e n h a n c e   l l i n   h a n g - u p   a n d   u t i l i z a t i o n   .\n",
      "\n",
      "Length of chars: 208\n",
      "\n",
      "Vectorized chars:\n",
      "[[ 5 11 12 16  9  3  2  8  8  5  6 10  7 15  4 25  2 10  3  8  4  5 12 20\n",
      "   5  9 11  7  6 10 16 11  3  2 10  4  6  3 13  2 14 12  5  3  2  5 16 24\n",
      "   8  2 18  4  7  6  7 17  3  7 18  7  3  7  2 21  5 12 16  5  3  2  3 13\n",
      "   2  2 17 17  2 11  3  4 21  2  6  2  9  9  7 17 10  4 17 17  2  8  2  6\n",
      "   3  5 14 14  8  7  5 11 13  2  9  3  7 14  7  9  3 12 12  4  6 11  5 15\n",
      "  14  5  4 18  6 13  7 15  2 21  4  9  4  3  9  6 16 15 22  2  8  7 17 21\n",
      "   4  9  4  3  9  5  6 10  3  4 15  4  6 18 22 19 21  7 12 16  6  3  2  2\n",
      "   8  9  3  7  2  6 13  5  6 11  2 12 12  4  6 13  5  6 18 16 14  5  6 10\n",
      "  16  3  4 12  4 25  5  3  4  7  6  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]]\n",
      "\n",
      "Length of vectorized chars: 290\n"
     ]
    }
   ],
   "source": [
    "# Test out character vectorizer\n",
    "random_train_chars = random.choice(train_chars)\n",
    "print(f\"Charified text:\\n{random_train_chars}\")\n",
    "print(f\"\\nLength of chars: {len(random_train_chars.split())}\")\n",
    "vectorized_chars = char_vectorizer([random_train_chars])\n",
    "print(f\"\\nVectorized chars:\\n{vectorized_chars}\")\n",
    "print(f\"\\nLength of vectorized chars: {len(vectorized_chars[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charified text (before vectorization and embedding):\n",
      "a   c l u s t e r   r a n d o m i z e d   t r i a l   w a s   c o n d u c t e d   i n   t h e   p l a t e a u x   r e g i o n   o f   t o g o   t o   e v a l u a t e   t h e   e f f e c t i v e n e s s   o f   d i f f e r e n t   a p p r o a c h e s   t o   p o s t - l l i n   c a m p a i g n   h o m e   v i s i t s   (   n u m b e r   o f   v i s i t s   a n d   t i m i n g   )   b y   v o l u n t e e r s   t o   e n h a n c e   l l i n   h a n g - u p   a n d   u t i l i z a t i o n   .\n",
      "\n",
      "Embedded chars (after vectorization and embedding):\n",
      "[[[-0.03065842  0.00746451  0.04872673 ... -0.03510648  0.04926255\n",
      "    0.03214253]\n",
      "  [-0.03727605 -0.03128933  0.00894328 ... -0.03571972 -0.00857221\n",
      "   -0.01504933]\n",
      "  [-0.00717763  0.04229415 -0.0306218  ... -0.00797784 -0.04055427\n",
      "   -0.00247294]\n",
      "  ...\n",
      "  [ 0.03154239 -0.04072635  0.03916179 ... -0.00918925 -0.03120901\n",
      "   -0.03665964]\n",
      "  [ 0.03154239 -0.04072635  0.03916179 ... -0.00918925 -0.03120901\n",
      "   -0.03665964]\n",
      "  [ 0.03154239 -0.04072635  0.03916179 ... -0.00918925 -0.03120901\n",
      "   -0.03665964]]]\n",
      "\n",
      "Character embedding shape: (1, 290, 25)\n"
     ]
    }
   ],
   "source": [
    "# Create char embedding layer\n",
    "char_embed = layers.Embedding(input_dim=NUM_CHAR_TOKENS, # number of different characters\n",
    "                              output_dim=25, # embedding dimension of each character (same as Figure 1 in https://arxiv.org/pdf/1612.05251.pdf)\n",
    "                              mask_zero=False, # don't use masks (this messes up model_5 if set to True)\n",
    "                              name=\"char_embed\")\n",
    "\n",
    "# Test out character embedding layer\n",
    "print(f\"Charified text (before vectorization and embedding):\\n{random_train_chars}\\n\")\n",
    "char_embed_example = char_embed(char_vectorizer([random_train_chars]))\n",
    "print(f\"Embedded chars (after vectorization and embedding):\\n{char_embed_example}\\n\")\n",
    "print(f\"Character embedding shape: {char_embed_example.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Conv1D on chars only\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "char_vectors = char_vectorizer(inputs)\n",
    "char_embeddings = char_embed(char_vectors)\n",
    "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(char_embeddings)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "model_3 = tf.keras.Model(inputs=inputs,\n",
    "                         outputs=outputs,\n",
    "                         name=\"model_3_conv1D_char_embedding\")\n",
    "\n",
    "# Compile model\n",
    "model_3.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3_conv1D_char_embedding\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " char_vectorizer (TextVector  (None, 290)              0         \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " char_embed (Embedding)      (None, 290, 25)           1750      \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 290, 64)           8064      \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 64)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,139\n",
      "Trainable params: 10,139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check the summary of conv1d_char_model\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None,), (None, 5)), types: (tf.string, tf.float64)>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create char datasets\n",
    "train_char_dataset = tf.data.Dataset.from_tensor_slices((train_chars, train_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_char_dataset = tf.data.Dataset.from_tensor_slices((val_chars, val_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_char_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 7s 12ms/step - loss: 1.2536 - accuracy: 0.4878 - val_loss: 1.0540 - val_accuracy: 0.5854\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 6s 11ms/step - loss: 1.0242 - accuracy: 0.5936 - val_loss: 0.9602 - val_accuracy: 0.6257\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 6s 11ms/step - loss: 0.9469 - accuracy: 0.6283 - val_loss: 0.8916 - val_accuracy: 0.6513\n"
     ]
    }
   ],
   "source": [
    "# Fit the model on chars only\n",
    "model_3_history = model_3.fit(train_char_dataset,\n",
    "                              steps_per_epoch=int(0.1 * len(train_char_dataset)),\n",
    "                              epochs=3,\n",
    "                              validation_data=val_char_dataset,\n",
    "                              validation_steps=int(0.1 * len(val_char_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 2s 2ms/step - loss: 0.9128 - accuracy: 0.6434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9128291606903076, 0.6434198617935181]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model_3 on whole validation char dataset\n",
    "model_3.evaluate(val_char_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24873124, 0.36918154, 0.09611895, 0.21510871, 0.07085959],\n",
       "       [0.20290062, 0.5726787 , 0.04434115, 0.12614551, 0.05393406],\n",
       "       [0.1126081 , 0.2708677 , 0.247974  , 0.23966919, 0.12888108],\n",
       "       ...,\n",
       "       [0.01988752, 0.06259876, 0.10684798, 0.04264515, 0.7680206 ],\n",
       "       [0.02427135, 0.08056268, 0.38754985, 0.04248876, 0.4651273 ],\n",
       "       [0.49525702, 0.30755866, 0.0863312 , 0.0970839 , 0.01376923]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with character model only\n",
    "model_3_pred_probs = model_3.predict(val_char_dataset)\n",
    "model_3_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([1, 1, 1, ..., 4, 4, 0])>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert predictions to classes\n",
    "model_3_preds = tf.argmax(model_3_pred_probs, axis=1)\n",
    "model_3_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 64.34198331788693,\n",
       " 'precision': 0.6330444458796689,\n",
       " 'recall': 0.6434198331788693,\n",
       " 'f1': 0.635045496123272}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Conv1D char only model results\n",
    "model_3_results = calculate_results(y_true=val_labels_encoded,\n",
    "                                        y_pred=model_3_preds)\n",
    "model_3_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup token inputs/model\n",
    "token_inputs = layers.Input(shape=[], dtype=tf.string, name=\"token_input\")\n",
    "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
    "token_output = layers.Dense(128, activation=\"relu\")(token_embeddings)\n",
    "token_model = tf.keras.Model(inputs=token_inputs,\n",
    "                             outputs=token_output)\n",
    "\n",
    "# 2. Setup char inputs/model\n",
    "char_inputs = layers.Input(shape=(1,), dtype=tf.string, name=\"char_input\")\n",
    "char_vectors = char_vectorizer(char_inputs)\n",
    "char_embeddings = char_embed(char_vectors)\n",
    "char_bi_lstm = layers.Bidirectional(layers.LSTM(25))(char_embeddings) # bi-LSTM shown in Figure 1 of https://arxiv.org/pdf/1612.05251.pdf\n",
    "char_model = tf.keras.Model(inputs=char_inputs,\n",
    "                            outputs=char_bi_lstm)\n",
    "\n",
    "# 3. Concatenate token and char inputs (create hybrid token embedding)\n",
    "token_char_concat = layers.Concatenate(name=\"token_char_hybrid\")([token_model.output, \n",
    "                                                                  char_model.output])\n",
    "\n",
    "# 4. Create output layers - addition of dropout discussed in 4.2 of https://arxiv.org/pdf/1612.05251.pdf\n",
    "combined_dropout = layers.Dropout(0.5)(token_char_concat)\n",
    "combined_dense = layers.Dense(200, activation=\"relu\")(combined_dropout) # slightly different to Figure 1 due to different shapes of token/char embedding layers\n",
    "final_dropout = layers.Dropout(0.5)(combined_dense)\n",
    "output_layer = layers.Dense(num_classes, activation=\"softmax\")(final_dropout)\n",
    "\n",
    "# 5. Construct model with char and token inputs\n",
    "model_4 = tf.keras.Model(inputs=[token_model.input, char_model.input],\n",
    "                         outputs=output_layer,\n",
    "                         name=\"model_4_token_and_char_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4_token_and_char_embeddings\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " char_input (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " token_input (InputLayer)       [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " char_vectorizer (TextVectoriza  (None, 290)         0           ['char_input[0][0]']             \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " universal_sentence_encoder (Ke  (None, 512)         256797824   ['token_input[0][0]']            \n",
      " rasLayer)                                                                                        \n",
      "                                                                                                  \n",
      " char_embed (Embedding)         (None, 290, 25)      1750        ['char_vectorizer[1][0]']        \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 128)          65664       ['universal_sentence_encoder[1][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 50)           10200       ['char_embed[1][0]']             \n",
      "                                                                                                  \n",
      " token_char_hybrid (Concatenate  (None, 178)         0           ['dense_5[0][0]',                \n",
      " )                                                                'bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 178)          0           ['token_char_hybrid[0][0]']      \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 200)          35800       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 200)          0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 5)            1005        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 256,912,243\n",
      "Trainable params: 114,419\n",
      "Non-trainable params: 256,797,824\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get summary of token and character model\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "# Plot hybrid token and character model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile token char model\n",
    "model_4.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(), # section 4.2 of https://arxiv.org/pdf/1612.05251.pdf mentions using SGD but we'll stick with Adam\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine chars and tokens into a dataset\n",
    "train_char_token_data = tf.data.Dataset.from_tensor_slices((train_sentences, train_chars)) # make data\n",
    "train_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot) # make labels\n",
    "train_char_token_dataset = tf.data.Dataset.zip((train_char_token_data, train_char_token_labels)) # combine data and labels\n",
    "\n",
    "# Prefetch and batch train data\n",
    "train_char_token_dataset = train_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) \n",
    "\n",
    "# Repeat same steps validation data\n",
    "val_char_token_data = tf.data.Dataset.from_tensor_slices((val_sentences, val_chars))\n",
    "val_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
    "val_char_token_dataset = tf.data.Dataset.zip((val_char_token_data, val_char_token_labels))\n",
    "val_char_token_dataset = val_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PrefetchDataset shapes: (((None,), (None,)), (None, 5)), types: ((tf.string, tf.string), tf.float64)>,\n",
       " <PrefetchDataset shapes: (((None,), (None,)), (None, 5)), types: ((tf.string, tf.string), tf.float64)>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out training char and token embedding dataset\n",
    "train_char_token_dataset, val_char_token_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 49s 81ms/step - loss: 0.9638 - accuracy: 0.6149 - val_loss: 0.7827 - val_accuracy: 0.6938\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 44s 79ms/step - loss: 0.7929 - accuracy: 0.6931 - val_loss: 0.7137 - val_accuracy: 0.7274\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 44s 78ms/step - loss: 0.7695 - accuracy: 0.7042 - val_loss: 0.6852 - val_accuracy: 0.7397\n"
     ]
    }
   ],
   "source": [
    "# Fit the model on tokens and chars\n",
    "model_4_history = model_4.fit(train_char_token_dataset, # train on dataset of token and characters\n",
    "                              steps_per_epoch=int(0.1 * len(train_char_token_dataset)),\n",
    "                              epochs=3,\n",
    "                              validation_data=val_char_token_dataset,\n",
    "                              validation_steps=int(0.1 * len(val_char_token_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 18s 19ms/step - loss: 0.6942 - accuracy: 0.7349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6941543221473694, 0.7348735332489014]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on the whole validation dataset\n",
    "model_4.evaluate(val_char_token_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.6982896e-01, 2.8905421e-01, 2.5235328e-03, 2.3037745e-01,\n",
       "        8.2158633e-03],\n",
       "       [3.8505733e-01, 4.0814379e-01, 2.2279026e-03, 2.0363553e-01,\n",
       "        9.3545712e-04],\n",
       "       [3.2090858e-01, 1.1310462e-01, 4.7008649e-02, 4.8621020e-01,\n",
       "        3.2768007e-02],\n",
       "       ...,\n",
       "       [4.6225340e-04, 8.1377979e-03, 5.1440708e-02, 1.6334825e-04,\n",
       "        9.3979591e-01],\n",
       "       [5.4579354e-03, 6.4294420e-02, 1.5375635e-01, 2.7210324e-03,\n",
       "        7.7377033e-01],\n",
       "       [3.5514361e-01, 4.2260265e-01, 1.4517145e-01, 4.0330283e-02,\n",
       "        3.6752053e-02]], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions using the token-character model hybrid\n",
    "model_4_pred_probs = model_4.predict(val_char_token_dataset)\n",
    "model_4_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 1, 3, ..., 4, 4, 1])>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn prediction probabilities into prediction classes\n",
    "model_4_preds = tf.argmax(model_4_pred_probs, axis=1)\n",
    "model_4_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 73.4873560174765,\n",
       " 'precision': 0.7346447325020511,\n",
       " 'recall': 0.734873560174765,\n",
       " 'f1': 0.7326708460745452}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get results of token-char-hybrid model\n",
    "model_4_results = calculate_results(y_true=val_labels_encoded,\n",
    "                                    y_pred=model_4_preds)\n",
    "model_4_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>line_number</th>\n",
       "      <th>total_lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>a total of @ patients with primary knee oa wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>outcome measures included pain reduction and i...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>pain was assessed using the visual analog pain...</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>secondary outcome measures included the wester...</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      target                                               text  line_number  \\\n",
       "0  OBJECTIVE  to investigate the efficacy of @ weeks of dail...            0   \n",
       "1    METHODS  a total of @ patients with primary knee oa wer...            1   \n",
       "2    METHODS  outcome measures included pain reduction and i...            2   \n",
       "3    METHODS  pain was assessed using the visual analog pain...            3   \n",
       "4    METHODS  secondary outcome measures included the wester...            4   \n",
       "\n",
       "   total_lines  \n",
       "0           11  \n",
       "1           11  \n",
       "2           11  \n",
       "3           11  \n",
       "4           11  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect training dataframe\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     15000\n",
       "1     15000\n",
       "2     15000\n",
       "3     15000\n",
       "4     14992\n",
       "5     14949\n",
       "6     14758\n",
       "7     14279\n",
       "8     13346\n",
       "9     11981\n",
       "10    10041\n",
       "11     7892\n",
       "12     5853\n",
       "13     4152\n",
       "14     2835\n",
       "15     1861\n",
       "16     1188\n",
       "17      751\n",
       "18      462\n",
       "19      286\n",
       "20      162\n",
       "21      101\n",
       "22       66\n",
       "23       33\n",
       "24       22\n",
       "25       14\n",
       "26        7\n",
       "27        4\n",
       "28        3\n",
       "29        1\n",
       "30        1\n",
       "Name: line_number, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many different line numbers are there?\n",
    "train_df[\"line_number\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the distribution of \"line_number\" column\n",
    "train_df.line_number.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use TensorFlow to create one-hot-encoded tensors of our \"line_number\" column \n",
    "train_line_numbers_one_hot = tf.one_hot(train_df[\"line_number\"].to_numpy(), depth=15)\n",
    "val_line_numbers_one_hot = tf.one_hot(val_df[\"line_number\"].to_numpy(), depth=15)\n",
    "test_line_numbers_one_hot = tf.one_hot(test_df[\"line_number\"].to_numpy(), depth=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([180040, 15]),\n",
       " <tf.Tensor: shape=(20, 15), dtype=float32, numpy=\n",
       " array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "       dtype=float32)>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check one-hot encoded \"line_number\" feature samples\n",
    "train_line_numbers_one_hot.shape, train_line_numbers_one_hot[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([180040, 20]),\n",
       " <tf.Tensor: shape=(10, 20), dtype=float32, numpy=\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]], dtype=float32)>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use TensorFlow to create one-hot-encoded tensors of our \"total_lines\" column \n",
    "train_total_lines_one_hot = tf.one_hot(train_df[\"total_lines\"].to_numpy(), depth=20)\n",
    "val_total_lines_one_hot = tf.one_hot(val_df[\"total_lines\"].to_numpy(), depth=20)\n",
    "test_total_lines_one_hot = tf.one_hot(test_df[\"total_lines\"].to_numpy(), depth=20)\n",
    "\n",
    "# Check shape and samples of total lines one-hot tensor\n",
    "train_total_lines_one_hot.shape, train_total_lines_one_hot[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Token inputs\n",
    "token_inputs = layers.Input(shape=[], dtype=\"string\", name=\"token_inputs\")\n",
    "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
    "token_outputs = layers.Dense(128, activation=\"relu\")(token_embeddings)\n",
    "token_model = tf.keras.Model(inputs=token_inputs,\n",
    "                             outputs=token_outputs)\n",
    "\n",
    "# 2. Char inputs\n",
    "char_inputs = layers.Input(shape=(1,), dtype=\"string\", name=\"char_inputs\")\n",
    "char_vectors = char_vectorizer(char_inputs)\n",
    "char_embeddings = char_embed(char_vectors)\n",
    "char_bi_lstm = layers.Bidirectional(layers.LSTM(32))(char_embeddings)\n",
    "char_model = tf.keras.Model(inputs=char_inputs,\n",
    "                            outputs=char_bi_lstm)\n",
    "\n",
    "# 3. Line numbers inputs\n",
    "line_number_inputs = layers.Input(shape=(15,), dtype=tf.int32, name=\"line_number_input\")\n",
    "x = layers.Dense(32, activation=\"relu\")(line_number_inputs)\n",
    "line_number_model = tf.keras.Model(inputs=line_number_inputs,\n",
    "                                   outputs=x)\n",
    "\n",
    "# 4. Total lines inputs\n",
    "total_lines_inputs = layers.Input(shape=(20,), dtype=tf.int32, name=\"total_lines_input\")\n",
    "y = layers.Dense(32, activation=\"relu\")(total_lines_inputs)\n",
    "total_line_model = tf.keras.Model(inputs=total_lines_inputs,\n",
    "                                  outputs=y)\n",
    "\n",
    "# 5. Combine token and char embeddings into a hybrid embedding\n",
    "combined_embeddings = layers.Concatenate(name=\"token_char_hybrid_embedding\")([token_model.output, \n",
    "                                                                              char_model.output])\n",
    "z = layers.Dense(256, activation=\"relu\")(combined_embeddings)\n",
    "z = layers.Dropout(0.5)(z)\n",
    "\n",
    "# 6. Combine positional embeddings with combined token and char embeddings into a tribrid embedding\n",
    "z = layers.Concatenate(name=\"token_char_positional_embedding\")([line_number_model.output,\n",
    "                                                                total_line_model.output,\n",
    "                                                                z])\n",
    "\n",
    "# 7. Create output layer\n",
    "output_layer = layers.Dense(5, activation=\"softmax\", name=\"output_layer\")(z)\n",
    "\n",
    "# 8. Put together model\n",
    "model_5 = tf.keras.Model(inputs=[line_number_model.input,\n",
    "                                 total_line_model.input,\n",
    "                                 token_model.input, \n",
    "                                 char_model.input],\n",
    "                         outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " char_inputs (InputLayer)       [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " token_inputs (InputLayer)      [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " char_vectorizer (TextVectoriza  (None, 290)         0           ['char_inputs[0][0]']            \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " universal_sentence_encoder (Ke  (None, 512)         256797824   ['token_inputs[0][0]']           \n",
      " rasLayer)                                                                                        \n",
      "                                                                                                  \n",
      " char_embed (Embedding)         (None, 290, 25)      1750        ['char_vectorizer[2][0]']        \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 128)          65664       ['universal_sentence_encoder[2][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 64)          14848       ['char_embed[2][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " token_char_hybrid_embedding (C  (None, 192)         0           ['dense_8[0][0]',                \n",
      " oncatenate)                                                      'bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " line_number_input (InputLayer)  [(None, 15)]        0           []                               \n",
      "                                                                                                  \n",
      " total_lines_input (InputLayer)  [(None, 20)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 256)          49408       ['token_char_hybrid_embedding[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 32)           512         ['line_number_input[0][0]']      \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 32)           672         ['total_lines_input[0][0]']      \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 256)          0           ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " token_char_positional_embeddin  (None, 320)         0           ['dense_9[0][0]',                \n",
      " g (Concatenate)                                                  'dense_10[0][0]',               \n",
      "                                                                  'dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " output_layer (Dense)           (None, 5)            1605        ['token_char_positional_embedding\n",
      "                                                                 [0][0]']                         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 256,932,283\n",
      "Trainable params: 134,459\n",
      "Non-trainable params: 256,797,824\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get a summary of our token, char and positional embedding model\n",
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x18396c340> True\n",
      "<keras.engine.input_layer.InputLayer object at 0x1839650a0> True\n",
      "<keras.layers.preprocessing.text_vectorization.TextVectorization object at 0x184e10bb0> True\n",
      "<tensorflow_hub.keras_layer.KerasLayer object at 0x17ca50280> False\n",
      "<keras.layers.embeddings.Embedding object at 0x182cd18b0> True\n",
      "<keras.layers.core.dense.Dense object at 0x183965340> True\n",
      "<keras.layers.wrappers.Bidirectional object at 0x1839c3c70> True\n",
      "<keras.layers.merge.Concatenate object at 0x183ac1040> True\n",
      "<keras.engine.input_layer.InputLayer object at 0x183a96b80> True\n",
      "<keras.engine.input_layer.InputLayer object at 0x183a729d0> True\n",
      "<keras.layers.core.dense.Dense object at 0x183ac1e50> True\n",
      "<keras.layers.core.dense.Dense object at 0x182e28eb0> True\n",
      "<keras.layers.core.dense.Dense object at 0x183a72cd0> True\n",
      "<keras.layers.core.dropout.Dropout object at 0x183ac1dc0> True\n",
      "<keras.layers.merge.Concatenate object at 0x183998850> True\n",
      "<keras.layers.core.dense.Dense object at 0x183acc9d0> True\n"
     ]
    }
   ],
   "source": [
    "# Check which layers of our model are trainable or not\n",
    "for layer in model_5.layers:\n",
    "  print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile token, char, positional embedding model\n",
    "model_5.compile(loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2), # add label smoothing (examples which are really confident get smoothed a little)\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PrefetchDataset shapes: (((None, 15), (None, 20), (None,), (None,)), (None, 5)), types: ((tf.float32, tf.float32, tf.string, tf.string), tf.float64)>,\n",
       " <PrefetchDataset shapes: (((None, 15), (None, 20), (None,), (None,)), (None, 5)), types: ((tf.float32, tf.float32, tf.string, tf.string), tf.float64)>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create training and validation datasets (all four kinds of inputs)\n",
    "train_pos_char_token_data = tf.data.Dataset.from_tensor_slices((train_line_numbers_one_hot, # line numbers\n",
    "                                                                train_total_lines_one_hot, # total lines\n",
    "                                                                train_sentences, # train tokens\n",
    "                                                                train_chars)) # train chars\n",
    "train_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot) # train labels\n",
    "train_pos_char_token_dataset = tf.data.Dataset.zip((train_pos_char_token_data, train_pos_char_token_labels)) # combine data and labels\n",
    "train_pos_char_token_dataset = train_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # turn into batches and prefetch appropriately\n",
    "\n",
    "# Validation dataset\n",
    "val_pos_char_token_data = tf.data.Dataset.from_tensor_slices((val_line_numbers_one_hot,\n",
    "                                                              val_total_lines_one_hot,\n",
    "                                                              val_sentences,\n",
    "                                                              val_chars))\n",
    "val_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
    "val_pos_char_token_dataset = tf.data.Dataset.zip((val_pos_char_token_data, val_pos_char_token_labels))\n",
    "val_pos_char_token_dataset = val_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # turn into batches and prefetch appropriately\n",
    "\n",
    "# Check input shapes\n",
    "train_pos_char_token_dataset, val_pos_char_token_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 52s 86ms/step - loss: 1.1088 - accuracy: 0.7125 - val_loss: 0.9860 - val_accuracy: 0.8032\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 46s 82ms/step - loss: 0.9704 - accuracy: 0.8148 - val_loss: 0.9514 - val_accuracy: 0.8285\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 45s 81ms/step - loss: 0.9528 - accuracy: 0.8234 - val_loss: 0.9382 - val_accuracy: 0.8305\n"
     ]
    }
   ],
   "source": [
    "# Fit the token, char and positional embedding model\n",
    "history_model_5 = model_5.fit(train_pos_char_token_dataset,\n",
    "                              steps_per_epoch=int(0.1 * len(train_pos_char_token_dataset)),\n",
    "                              epochs=3,\n",
    "                              validation_data=val_pos_char_token_dataset,\n",
    "                              validation_steps=int(0.1 * len(val_pos_char_token_dataset)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c9864355dd93ab20d4e3408f8fe9e92a27fc5b675de245446a36fefcf676fab5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
